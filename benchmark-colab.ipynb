{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/corydambach/mmrotate-sandbox"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xK-iG0pKlaPc",
        "outputId": "cb0ea520-1d09-4ca6-e56b-14d70aab1ec6"
      },
      "id": "xK-iG0pKlaPc",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'mmrotate-sandbox'...\n",
            "remote: Enumerating objects: 55, done.\u001b[K\n",
            "remote: Counting objects: 100% (55/55), done.\u001b[K\n",
            "remote: Compressing objects: 100% (39/39), done.\u001b[K\n",
            "remote: Total 55 (delta 15), reused 52 (delta 13), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (55/55), 273.91 KiB | 22.83 MiB/s, done.\n",
            "Resolving deltas: 100% (15/15), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd mmrotate-sandbox/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWYzZe5_ljRQ",
        "outputId": "811fff58-ee39-445f-ae3b-14ddf48dd277"
      },
      "id": "YWYzZe5_ljRQ",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/mmrotate-sandbox\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q torch==2.0.1 torchvision==0.15.2 torchaudio==2.0.2 \"numpy<2\" --index-url https://download.pytorch.org/whl/cu118\n",
        "!pip install -q -U openmim \"numpy<2\"\n",
        "# Install MMCV compiled for PyTorch 2.0.1 (not 2.1.0)\n",
        "!pip install -q mmcv-full==1.7.2 -f https://download.openmmlab.com/mmcv/dist/cu118/torch2.0.0/index.html \"numpy<2\"\n",
        "!mim install -q mmdet\\<3.0.0\n",
        "!pip uninstall -q mmrotate --yes\n",
        "!rm -rf mmrotate\n",
        "!git clone -q https://github.com/open-mmlab/mmrotate.git\n",
        "!cd mmrotate && pip install -q -e .\n",
        "!mkdir model\n",
        "!wget -q -O ./model/redet_re50_fpn_1x_dota_ms_rr_le90-fc9217b5.pth https://download.openmmlab.com/mmrotate/v0.1.0/redet/redet_re50_fpn_1x_dota_ms_rr_le90/redet_re50_fpn_1x_dota_ms_rr_le90-fc9217b5.pth"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ZsfK08UWlrr8",
        "outputId": "c88ae4ea-a77e-4322-fb75-8e637e2e1d45"
      },
      "id": "ZsfK08UWlrr8",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 GB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m114.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m97.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m76.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.3/132.3 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for lit (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.3 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.3 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.3 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.5/259.5 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.1/50.1 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.7/89.7 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m449.6/449.6 kB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m60.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.5/311.5 kB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.4/239.4 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m506.5/506.5 kB\u001b[0m \u001b[31m40.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.2/144.2 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m86.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.1/953.1 kB\u001b[0m \u001b[31m51.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.5/99.5 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for oss2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for aliyun-python-sdk-core (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for crcmod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "google-colab 1.0.0 requires requests==2.32.3, but you have requests 2.28.2 which is incompatible.\n",
            "sphinx 8.2.3 requires requests>=2.30.0, but you have requests 2.28.2 which is incompatible.\n",
            "pymc 5.25.1 requires rich>=13.7.1, but you have rich 13.4.2 which is incompatible.\n",
            "datasets 4.0.0 requires requests>=2.32.2, but you have requests 2.28.2 which is incompatible.\n",
            "datasets 4.0.0 requires tqdm>=4.66.3, but you have tqdm 4.65.2 which is incompatible.\n",
            "yfinance 0.2.65 requires requests>=2.31, but you have requests 2.28.2 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "pytensor 2.31.7 requires filelock>=3.15, but you have filelock 3.14.0 which is incompatible.\n",
            "dataproc-spark-connect 0.8.3 requires tqdm>=4.67, but you have tqdm 4.65.2 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.4/70.4 MB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.8/46.8 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.0/63.0 MB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m256.2/256.2 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m68.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[33mWARNING: Skipping mmrotate as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.3/225.3 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "exit()"
      ],
      "metadata": {
        "id": "bIdN00rGoO0q"
      },
      "id": "bIdN00rGoO0q",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd mmrotate-sandbox/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2Wh9KCKsWDX",
        "outputId": "bbd9ec64-c49a-484d-b890-e03188a484df"
      },
      "id": "d2Wh9KCKsWDX",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'mmrotate-sandbox/'\n",
            "/content/mmrotate-sandbox\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#os\n",
        "import os\n",
        "\n",
        "#ml\n",
        "import numpy as np\n",
        "import torch\n",
        "import mmcv\n",
        "import cv2\n",
        "from mmdet.apis    import init_detector\n",
        "from mmrotate.apis import inference_detector_by_patches\n",
        "from dataclasses import asdict\n",
        "import json\n",
        "\n",
        "from geo_util import Pnt, Vehicle, VehicleExport, rbbox_to_poly\n"
      ],
      "metadata": {
        "id": "Kq2bE7U9rnkQ"
      },
      "id": "Kq2bE7U9rnkQ",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def process_results( result, conf_thr: float ):\n",
        "    if isinstance(result, tuple):\n",
        "        bbox_result, segm_result = result\n",
        "        if isinstance( segm_result, tuple ):\n",
        "            segm_result = segm_result[0]\n",
        "    else:\n",
        "        bbox_result, segm_result = result, None\n",
        "    bboxes = np.vstack(bbox_result)\n",
        "    labels = [\n",
        "        np.full( bbox.shape[0], i, dtype=np.int32 )\n",
        "        for i, bbox in enumerate(bbox_result)\n",
        "    ]\n",
        "    labels = np.concatenate( labels )\n",
        "    #remove everything that isn't a small vehicle\n",
        "    # Apply both filters together\n",
        "    conf_mask = bboxes[:, 5] >= conf_thr\n",
        "    class_mask = (labels == 4) | (labels == 5)\n",
        "    combined_mask = conf_mask & class_mask\n",
        "    bboxes = bboxes[combined_mask]\n",
        "    labels = labels[combined_mask]\n",
        "    # print( f\"Detected {len( bboxes )} vehicles.\" )\n",
        "    reshaped = labels.reshape( -1, 1 )\n",
        "    concat = np.concatenate( (bboxes, reshaped), axis=1 )\n",
        "    a_entries = [Vehicle( r[0], r[1], r[2], r[3], r[4], r[5], r ) for r in concat]\n",
        "    vas = [VehicleExport( Pnt( a.x, a.y ), a.width, a.height, a.theta, a.confidence, rbbox_to_poly( a.arr ).tolist(), str(i) ) for i, a in enumerate(a_entries)]\n",
        "    return vas\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "PXZ5_F6Opphe"
      },
      "id": "PXZ5_F6Opphe",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class InitArgs:\n",
        "    def __init__(self):\n",
        "        self.device     = 'cuda:0'\n",
        "        self.config     = \"mmrotate/configs/redet/redet_re50_refpn_1x_dota_ms_rr_le90.py\"\n",
        "        self.checkpoint = \"model/redet_re50_fpn_1x_dota_ms_rr_le90-fc9217b5.pth\"\n",
        "\n",
        "class Args:\n",
        "    def __init__( self, batch_size: int, patch_size: int, patch_step: int, img: str, conf: float ):\n",
        "        self.img = img\n",
        "        self.score_thr = conf\n",
        "        self.merge_iou_thr = 0.85\n",
        "        self.img_ratios = [1.0]\n",
        "        self.batch_size = batch_size\n",
        "        self.patch_sizes = [patch_size]\n",
        "        self.patch_steps = [patch_step]\n",
        "        self.palette = 'dota'\n",
        "\n",
        "torch.cuda.set_per_process_memory_fraction( 1.0 )\n",
        "init_args = InitArgs()\n",
        "\n"
      ],
      "metadata": {
        "id": "yy7jv9sMprg2"
      },
      "id": "yy7jv9sMprg2",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "try:\n",
        "    model\n",
        "except NameError:\n",
        "    model = init_detector( init_args.config, init_args.checkpoint, device=init_args.device )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K_KnxS1HptrI",
        "outputId": "41b8fac0-15b8-426d-c21d-5e102dfb454b"
      },
      "id": "K_KnxS1HptrI",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/mmrotate-sandbox/mmrotate/mmrotate/models/backbones/re_resnet.py:481: UserWarning: DeprecationWarning: pretrained is deprecated, please use \"init_cfg\" instead\n",
            "  warnings.warn('DeprecationWarning: pretrained is deprecated, '\n",
            "/usr/local/lib/python3.11/dist-packages/e2cnn/nn/modules/r2_conv/basisexpansion_singleblock.py:80: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at ../aten/src/ATen/native/IndexingUtils.h:27.)\n",
            "  full_mask[mask] = norms.to(torch.uint8)\n",
            "/usr/local/lib/python3.11/dist-packages/mmdet/models/dense_heads/anchor_head.py:116: UserWarning: DeprecationWarning: `num_anchors` is deprecated, for consistency or also use `num_base_priors` instead\n",
            "  warnings.warn('DeprecationWarning: `num_anchors` is deprecated, '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "load checkpoint from local path: model/redet_re50_fpn_1x_dota_ms_rr_le90-fc9217b5.pth\n",
            "The model and loaded state dict do not match exactly\n",
            "\n",
            "missing keys in source state_dict: backbone.conv1.filter, backbone.layer2.0.conv1.filter, backbone.layer2.0.conv2.filter, backbone.layer2.0.conv3.filter, backbone.layer2.0.downsample.0.filter, backbone.layer2.1.conv1.filter, backbone.layer2.1.conv2.filter, backbone.layer2.1.conv3.filter, backbone.layer2.2.conv1.filter, backbone.layer2.2.conv2.filter, backbone.layer2.2.conv3.filter, backbone.layer2.3.conv1.filter, backbone.layer2.3.conv2.filter, backbone.layer2.3.conv3.filter, backbone.layer3.0.conv1.filter, backbone.layer3.0.conv2.filter, backbone.layer3.0.conv3.filter, backbone.layer3.0.downsample.0.filter, backbone.layer3.1.conv1.filter, backbone.layer3.1.conv2.filter, backbone.layer3.1.conv3.filter, backbone.layer3.2.conv1.filter, backbone.layer3.2.conv2.filter, backbone.layer3.2.conv3.filter, backbone.layer3.3.conv1.filter, backbone.layer3.3.conv2.filter, backbone.layer3.3.conv3.filter, backbone.layer3.4.conv1.filter, backbone.layer3.4.conv2.filter, backbone.layer3.4.conv3.filter, backbone.layer3.5.conv1.filter, backbone.layer3.5.conv2.filter, backbone.layer3.5.conv3.filter, backbone.layer4.0.conv1.filter, backbone.layer4.0.conv2.filter, backbone.layer4.0.conv3.filter, backbone.layer4.0.downsample.0.filter, backbone.layer4.1.conv1.filter, backbone.layer4.1.conv2.filter, backbone.layer4.1.conv3.filter, backbone.layer4.2.conv1.filter, backbone.layer4.2.conv2.filter, backbone.layer4.2.conv3.filter, neck.lateral_convs.0.conv.expanded_bias, neck.lateral_convs.0.conv.filter, neck.lateral_convs.1.conv.expanded_bias, neck.lateral_convs.1.conv.filter, neck.lateral_convs.2.conv.expanded_bias, neck.lateral_convs.2.conv.filter, neck.lateral_convs.3.conv.expanded_bias, neck.lateral_convs.3.conv.filter, neck.fpn_convs.0.conv.expanded_bias, neck.fpn_convs.0.conv.filter, neck.fpn_convs.1.conv.expanded_bias, neck.fpn_convs.1.conv.filter, neck.fpn_convs.2.conv.expanded_bias, neck.fpn_convs.2.conv.filter, neck.fpn_convs.3.conv.expanded_bias, neck.fpn_convs.3.conv.filter\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import numpy as np\n",
        "from typing import List\n",
        "from PIL import Image\n",
        "\n",
        "def load_gt(img_path: str) -> List[VehicleExport]:\n",
        "    \"\"\"Load ground truth from corresponding .txt file\"\"\"\n",
        "    gt_path = Path(img_path).with_suffix('.txt')\n",
        "    if not gt_path.exists():\n",
        "        print(f\"Warning: GT file {gt_path} not found\")\n",
        "        return []\n",
        "\n",
        "    # Get image dims with fallback\n",
        "    try:\n",
        "        w, h = Image.open(img_path).size\n",
        "    except:\n",
        "        w, h = 1024, 1024\n",
        "        print(f\"Warning: Using default dims for {img_path}\")\n",
        "\n",
        "    vehicles = []\n",
        "    with open(gt_path, 'r') as f:\n",
        "        for line in f:\n",
        "            parts = line.strip().split()\n",
        "            if len(parts) < 6:\n",
        "                continue\n",
        "\n",
        "            cls, cx_n, cy_n, w_n, h_n, angle = map(float, parts[:6])\n",
        "            cx, cy, w_abs, h_abs = cx_n * w, cy_n * h, w_n * w, h_n * h\n",
        "\n",
        "            arr = np.array([cx, cy, w_abs, h_abs, angle, 1.0, cls])\n",
        "            poly = rbbox_to_poly(arr).tolist()\n",
        "\n",
        "            vehicles.append(VehicleExport(\n",
        "                label=int(cls), center=Pnt(cx, cy), width=w_abs,\n",
        "                height=h_abs, theta=angle, polygon=poly, confidence=1.0\n",
        "            ))\n",
        "\n",
        "    return vehicles\n",
        "\n",
        "def get_dist(p1, p2):\n",
        "    \"\"\"Euclidean distance between points\"\"\"\n",
        "    return np.sqrt((p1.x - p2.x)**2 + (p1.y - p2.y)**2)\n",
        "\n",
        "def find_matches(dets: List[VehicleExport], gt: List[VehicleExport], max_dist: float = 10.0):\n",
        "    \"\"\"Find nearest GT matches using greedy assignment\"\"\"\n",
        "    matches = []\n",
        "    used = set()\n",
        "\n",
        "    for i, det in enumerate(dets):\n",
        "        best_dist, best_j = float('inf'), -1\n",
        "\n",
        "        for j, g in enumerate(gt):\n",
        "            if j in used:\n",
        "                continue\n",
        "            dist = get_dist(det.center, g.center)\n",
        "            if dist < best_dist and dist <= max_dist:\n",
        "                best_dist, best_j = dist, j\n",
        "\n",
        "        if best_j != -1:\n",
        "            matches.append((i, best_j, best_dist))\n",
        "            used.add(best_j)\n",
        "\n",
        "    return matches\n",
        "\n"
      ],
      "metadata": {
        "id": "6TlZUfu3q5ar"
      },
      "id": "6TlZUfu3q5ar",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def benchmark(img_path: str, dets: List[VehicleExport]):\n",
        "    \"\"\"Simple benchmark using nearest center matching\"\"\"\n",
        "    gt = load_gt(img_path)\n",
        "    if not gt:\n",
        "        print(f\"No GT for {Path(img_path).name}\")\n",
        "        return\n",
        "\n",
        "    matches = find_matches(dets, gt, 10)\n",
        "\n",
        "    tp = len(matches)\n",
        "    fp = len(dets) - tp\n",
        "    fn = len(gt) - tp\n",
        "\n",
        "    prec = tp / len(dets) if dets else 0.0\n",
        "    rec = tp / len(gt) if gt else 0.0\n",
        "    f1 = 2 * prec * rec / (prec + rec) if prec + rec else 0.0\n",
        "\n",
        "    name = Path(img_path).name\n",
        "    print(f\"\\n{name}:\")\n",
        "    print(f\"Dets: {len(dets)}, GT: {len(gt)}\")\n",
        "    print(f\"Prec: {prec:.3f}, Rec: {rec:.3f}, F1: {f1:.3f}\")\n",
        "    print(f\"TP: {tp}, FP: {fp}, FN: {fn}\")\n",
        "\n",
        "    return {\n",
        "        'precision': prec, 'recall': rec, 'f1': f1,\n",
        "        'tp': tp, 'fp': fp, 'fn': fn, 'matches': matches\n",
        "    }\n",
        ""
      ],
      "metadata": {
        "id": "F7mnLbKopxgX"
      },
      "id": "F7mnLbKopxgX",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pathlib as path\n",
        "import glob\n",
        "\n",
        "dir  = \"./input\"\n",
        "imgs = txt_files = glob.glob(  f\"{dir}/*.png\" )\n",
        "for img_path in imgs:\n",
        "    args = Args( batch_size=32, patch_size=384, patch_step=64, img=img_path, conf=0.00 )\n",
        "    img = mmcv.imread( args.img )\n",
        "    result = inference_detector_by_patches( model, img,\n",
        "                                            args.patch_sizes,\n",
        "                                            args.patch_steps,\n",
        "                                            args.img_ratios,\n",
        "                                            args.merge_iou_thr,\n",
        "                                            args.batch_size )\n",
        "\n",
        "    dets = process_results( result, args.score_thr )\n",
        "    benchmark( img_path, dets )\n",
        "    # model.show_result( img, result, show=True )\n",
        "    #print( dets )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5v6euIqpylx",
        "outputId": "d6f4aa92-8464-4f1b-b06d-a3c198fc5370"
      },
      "id": "M5v6euIqpylx",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/mmdet/models/dense_heads/anchor_head.py:123: UserWarning: DeprecationWarning: anchor_generator is deprecated, please use \"prior_generator\" instead\n",
            "  warnings.warn('DeprecationWarning: anchor_generator is deprecated, '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "29.png:\n",
            "Dets: 258, GT: 200\n",
            "Prec: 0.729, Rec: 0.940, F1: 0.821\n",
            "TP: 188, FP: 70, FN: 12\n",
            "\n",
            "18.png:\n",
            "Dets: 55, GT: 38\n",
            "Prec: 0.636, Rec: 0.921, F1: 0.753\n",
            "TP: 35, FP: 20, FN: 3\n",
            "\n",
            "31.png:\n",
            "Dets: 34, GT: 29\n",
            "Prec: 0.765, Rec: 0.897, F1: 0.825\n",
            "TP: 26, FP: 8, FN: 3\n",
            "\n",
            "9.png:\n",
            "Dets: 128, GT: 86\n",
            "Prec: 0.625, Rec: 0.930, F1: 0.748\n",
            "TP: 80, FP: 48, FN: 6\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}