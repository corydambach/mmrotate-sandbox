{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#python libs\n",
    "import math\n",
    "import json\n",
    "from dataclasses import dataclass, asdict\n",
    "from typing import List\n",
    "from typing import Any\n",
    "\n",
    "#third party libs\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image, ImageDraw\n",
    "from rtree import index\n",
    "\n",
    "from configs.redet.util import MatchExport\n",
    "from configs.redet.util import Vehicle\n",
    "from configs.redet.util import euclidean_distance\n",
    "from configs.redet.util import Pnt, VehicleExport, crop_polygon, get_mean_color, rbbox_to_poly, upscale_2x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self, dist_thr: float, width_thr: float, height_thr: float, color_thr: float):\n",
    "        self.imgA = \"./PA-SM-2020-06-12/satellite-sm.png\"\n",
    "        self.imgB = \"./PA-SM-2020-10-17/satellite-sm.png\"\n",
    "        self.resA = \"./pa-sm-2020-06-12-sm-gpu.npy\"\n",
    "        self.resB = \"./pa-sm-2020-10-17-sm-gpu.npy\"\n",
    "        self.dist_thr = dist_thr\n",
    "        self.width_thr = width_thr\n",
    "        self.height_thr = height_thr\n",
    "        self.color_thr = color_thr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Args(\n",
    "    dist_thr=7.0,\n",
    "    width_thr=6.0,\n",
    "    height_thr=6.0,\n",
    "    color_thr=10.0 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_reg( a: Image, b: Image ):\n",
    "    img_a = cv2.cvtColor( np.array( a ), cv2.COLOR_RGB2BGR )\n",
    "    img_b = cv2.cvtColor( np.array( b ), cv2.COLOR_RGB2BGR )\n",
    "\n",
    "    # convert the images to grayscale\n",
    "    a_gray = cv2.cvtColor(img_a, cv2.COLOR_BGR2GRAY)\n",
    "    b_gray = cv2.cvtColor(img_b, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # create SIFT object to detect keypoints and compute descriptors\n",
    "    sift = cv2.SIFT_create()\n",
    "    kps1, descriptors1 = sift.detectAndCompute(a_gray, None)\n",
    "    kps2, descriptors2 = sift.detectAndCompute(b_gray, None)\n",
    "\n",
    "    # create and use flann matcher\n",
    "    matcher = cv2.FlannBasedMatcher()\n",
    "    matches = matcher.knnMatch(descriptors1, descriptors2, k=2)\n",
    "\n",
    "    # apply ratio test to filter good matches\n",
    "    good_matches = []\n",
    "    ratio_threshold = 0.7\n",
    "    for m, n in matches:\n",
    "        if m.distance < ratio_threshold * n.distance:\n",
    "            good_matches.append(m)\n",
    "\n",
    "    # Extract the matched keypoints\n",
    "    ref_points    = np.float32([kps1[m.queryIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "    sensed_points = np.float32([kps2[m.trainIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "\n",
    "    # Estimate the homography matrix using RANSAC\n",
    "    homography, _ = cv2.findHomography(sensed_points, ref_points, cv2.RANSAC, 5.0)\n",
    "    return homography\n",
    "\n",
    "def translate( homography, coords ):\n",
    "    coords_homogeneous = np.array([[coord[0], coord[1], 1] for coord in coords])\n",
    "    translated_coords_homogeneous = homography.dot(coords_homogeneous.T).T\n",
    "    translated_coords = translated_coords_homogeneous[:, :2] / translated_coords_homogeneous[:, 2, np.newaxis]\n",
    "    return translated_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_dimensions( a: Vehicle, b: Vehicle ):\n",
    "    w_diff = abs( a.width - b.width   )\n",
    "    h_diff = abs( a.height - b.height )\n",
    "    # if w_diff > args.width_thr:\n",
    "    #     return False\n",
    "    # if h_diff > args.height_thr:\n",
    "    #     return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img_b must be registered already\n",
    "import PIL\n",
    "PIL.Image.MAX_IMAGE_PIXELS = 9331200000\n",
    "\n",
    "try:\n",
    "    img_a \n",
    "except NameError:\n",
    "    img_a = Image.open( args.imgA ).convert(\"RGBA\")\n",
    "\n",
    "try:\n",
    "    img_b \n",
    "except NameError:\n",
    "    img_b = Image.open( args.imgB ).convert(\"RGBA\")\n",
    "    \n",
    "ident = identity_homography = np.array([[1, 0, 0],\n",
    "                                        [0, 1, 0],\n",
    "                                        [0, 0, 1]], dtype=np.float32)\n",
    "try:\n",
    "    homography \n",
    "except NameError:\n",
    "    homography = ident #img_reg( args )\n",
    "\n",
    "# cv2.imwrite(\"out/registered_image.png\", img_registered )\n",
    "# img_b = Image.open( \"out/registered_image.png\" ).convert(\"RGBA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from mmrotate.core.bbox.transforms import norm_angle, obb2poly, obb2poly_le90, obb2poly_np_le90\n",
    "\n",
    "def poly2obb_le90(polys):\n",
    "    \"\"\"Convert polygons to oriented bounding boxes.\n",
    "    Args:\n",
    "        polys (torch.Tensor): [x0,y0,x1,y1,x2,y2,x3,y3]\n",
    "    Returns:\n",
    "        obbs (torch.Tensor): [x_ctr,y_ctr,w,h,angle]\n",
    "    \"\"\"\n",
    "    polys = torch.reshape(polys, [-1, 8])\n",
    "    pt1, pt2, pt3, pt4 = polys[..., :8].chunk(4, 1)\n",
    "    edge1 = torch.sqrt(\n",
    "        torch.pow(pt1[..., 0] - pt2[..., 0], 2) +\n",
    "        torch.pow(pt1[..., 1] - pt2[..., 1], 2))\n",
    "    edge2 = torch.sqrt(\n",
    "        torch.pow(pt2[..., 0] - pt3[..., 0], 2) +\n",
    "        torch.pow(pt2[..., 1] - pt3[..., 1], 2))\n",
    "    angles1 = torch.atan2((pt2[..., 1] - pt1[..., 1]),\n",
    "                          (pt2[..., 0] - pt1[..., 0]))\n",
    "    angles2 = torch.atan2((pt4[..., 1] - pt1[..., 1]),\n",
    "                          (pt4[..., 0] - pt1[..., 0]))\n",
    "    angles = polys.new_zeros(polys.shape[0])\n",
    "    angles[edge1 > edge2] = angles1[edge1 > edge2]\n",
    "    angles[edge1 <= edge2] = angles2[edge1 <= edge2]\n",
    "    angles = norm_angle(angles, 'le90')\n",
    "    x_ctr = (pt1[..., 0] + pt3[..., 0]) / 2.0\n",
    "    y_ctr = (pt1[..., 1] + pt3[..., 1]) / 2.0\n",
    "    edges = torch.stack([edge1, edge2], dim=1)\n",
    "    width, _ = torch.max(edges, 1)\n",
    "    height, _ = torch.min(edges, 1)\n",
    "    return torch.stack([x_ctr, y_ctr, width, height, angles], 1)\n",
    "\n",
    "def record_translate( rec: np.ndarray ):\n",
    "    poly       = torch.Tensor( rbbox_to_poly( rec ) )\n",
    "    translated = translate( homography, poly )\n",
    "    rbb = poly2obb_le90( torch.Tensor( translated ) )\n",
    "    return np.array( rbb[0], dtype=np.float64 )\n",
    "\n",
    "A = np.load( args.resA )\n",
    "B = np.load( args.resB )\n",
    "\n",
    "#untransformed versions\n",
    "a_entries = [Vehicle( r[0], r[1], r[2], r[3], r[4], r ) for r in A]\n",
    "b_trans   = [record_translate( r ) for r in B]\n",
    "b_entries = [Vehicle( r[0], r[1], r[2], r[3], r[4], r ) for r in b_trans]\n",
    "\n",
    "#build spatial indices\n",
    "a_qtree = index.Index()\n",
    "for i, a in enumerate( a_entries ):\n",
    "    a_qtree.insert( i, ( a.x, a.y ) )\n",
    "b_qtree = index.Index()\n",
    "for i, b in enumerate( b_entries ):\n",
    "    b_qtree.insert( i, ( b.x, b.y ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches: List[Vehicle] = []\n",
    "for i, a in enumerate( a_entries ):\n",
    "    b_ind = list( b_qtree.nearest( ( a.x, a.y ), 1, objects=True ) )[0].id\n",
    "    b     = b_entries[b_ind]\n",
    "    dist  = euclidean_distance( a.x, a.y, b.x, b.y )\n",
    "    if dist > args.dist_thr:\n",
    "        continue\n",
    "    # if not compare_dimensions( a, b ):\n",
    "    #     continue\n",
    "    matches.append( [a, b] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "import numpy as np\n",
    "\n",
    "def crop_polygon_with_alpha(img: Image.Image, poly: np.ndarray) -> Image.Image:\n",
    "    min_x, min_y = poly.min(axis=0).astype(int)\n",
    "    max_x, max_y = poly.max(axis=0).astype(int)    \n",
    "    crop = img.crop((min_x, min_y, max_x, max_y)).convert(\"RGBA\")    \n",
    "    local_poly = [(x - min_x, y - min_y) for x, y in poly]    \n",
    "    mask = Image.new(\"L\", crop.size, 0)\n",
    "    ImageDraw.Draw(mask).polygon(local_poly, fill=255)    \n",
    "    crop.putalpha(mask)\n",
    "    return crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import Dict, Tuple\n",
    "\n",
    "# ‚ù∂ --- a minimal named-colour table -------------------------\n",
    "CSS_NAMED_COLOURS: Dict[str, Tuple[int, int, int]] = {\n",
    "    \"black\":       (0,   0,   0),\n",
    "    \"white\":       (255, 255, 255),\n",
    "    \"red\":         (255, 0,   0),\n",
    "    \"lime\":        (0,   255, 0),\n",
    "    \"blue\":        (0,   0,   255),\n",
    "    \"yellow\":      (255, 255, 0),\n",
    "    \"cyan\":        (0,   255, 255),\n",
    "    \"magenta\":     (255, 0,   255),\n",
    "    \"gray\":        (128, 128, 128),\n",
    "    \"orange\":      (255, 165, 0),\n",
    "    \"brown\":       (165, 42,  42),\n",
    "    \"pink\":        (255, 192, 203),\n",
    "    # ‚Ä¶add as many as you like\n",
    "}\n",
    "\n",
    "# ‚ù∑ --- find nearest named colour ----------------------------\n",
    "def nearest_named_colour(rgb: np.ndarray,\n",
    "                         palette: Dict[str, Tuple[int, int, int]] = CSS_NAMED_COLOURS\n",
    "                        ) -> str:\n",
    "    \"\"\"\n",
    "    rgb      : (3,) uint8 array, e.g. array([123, 200,  34])\n",
    "    palette  : mapping name -> (R, G, B)\n",
    "\n",
    "    Returns the name with the smallest Euclidean distance in RGB space.\n",
    "    \"\"\"\n",
    "    diffs = {name: np.linalg.norm(rgb - np.array(col)) for name, col in palette.items()}\n",
    "    return min(diffs, key=diffs.get)\n",
    "\n",
    "# ‚ù∏ --- glue code for your K-means output --------------------\n",
    "def dominant_cluster_colour_name(centers: np.ndarray, counts: np.ndarray) -> str:\n",
    "    \"\"\"\n",
    "    centers : (k,3) uint8   - cluster centroids from K-means\n",
    "    counts  : (k,) int      - pixel counts per cluster\n",
    "\n",
    "    Returns a named colour string for the most-populous cluster.\n",
    "    \"\"\"\n",
    "    dominant_idx = np.argmax(counts)      # largest count\n",
    "    dominant_rgb = centers[dominant_idx]  # uint8 triplet\n",
    "    return nearest_named_colour(dominant_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import Tuple, Union\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def kmeans_palette(\n",
    "    img: Image.Image,\n",
    "    k: int = 8,\n",
    "    max_iter: int = 100,\n",
    "    random_state: int = 42,\n",
    ") -> Tuple[str, Image.Image]:\n",
    "    # ---- 1 ¬∑ gather pixels --------------------------------------------------\n",
    "    rgb = np.array(img.convert(\"RGB\")).reshape(-1, 3).astype(np.float32)\n",
    "\n",
    "    # ---- 2 ¬∑ K-means --------------------------------------------------------\n",
    "    km = KMeans(n_clusters=k, n_init=\"auto\",\n",
    "                max_iter=max_iter, random_state=random_state)\n",
    "    labels = km.fit_predict(rgb)\n",
    "    centers = km.cluster_centers_.astype(np.uint8)\n",
    "\n",
    "    # pixel share per cluster (sorted largest->smallest)\n",
    "    counts = np.bincount(labels)\n",
    "    order = np.argsort(counts)[::-1]          # dominant first\n",
    "    counts = counts[order]\n",
    "    centers = centers[order]\n",
    "    name = dominant_cluster_colour_name(centers, counts)\n",
    "\n",
    "    # normalised bar widths\n",
    "    frac = counts / counts.sum()\n",
    "    size = (256, 32)\n",
    "    w_px, h_px = size\n",
    "    widths = np.round(frac * w_px).astype(int)\n",
    "\n",
    "    # ---- 3 ¬∑ paint bar chart ------------------------------------------------\n",
    "    bar = Image.new(\"RGB\", size)\n",
    "    x = 0\n",
    "    for w, colour in zip(widths, centers):\n",
    "        if w == 0:            # very tiny clusters\n",
    "            continue\n",
    "        block = Image.new(\"RGB\", (w, h_px), tuple(colour))\n",
    "        bar.paste(block, (x, 0))\n",
    "        x += w\n",
    "    # if rounding left a gap at the end, fill it with the most dominant colour\n",
    "    if x < w_px:\n",
    "        bar.paste(Image.new(\"RGB\", (w_px - x, h_px), tuple(centers[0])), (x, 0))\n",
    "\n",
    "    return (name, bar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 403\n"
     ]
    }
   ],
   "source": [
    "lst: List[MatchExport] = []\n",
    "i: int = 0\n",
    "\n",
    "for match in matches:\n",
    "    a: Vehicle = match[0]\n",
    "    b: Vehicle = match[1]\n",
    "    crop_a = rbbox_to_poly( a.arr )\n",
    "    crop_b = rbbox_to_poly( b.arr )\n",
    "    va = VehicleExport( Pnt( a.x, a.y ), a.width, a.height, a.theta, crop_a.tolist(), str(i) )\n",
    "    vb = VehicleExport( Pnt( b.x, b.y ), b.width, b.height, b.theta, crop_b.tolist(), str(i) )\n",
    "\n",
    "    #get crop\n",
    "    img_crop_a = crop_polygon_with_alpha( img_a, crop_a )\n",
    "    img_crop_b = crop_polygon_with_alpha( img_b, crop_b )\n",
    "    # img_crop_a = img_crop_a.resize( upscale_2x( img_crop_a ), resample=Image.BOX )\n",
    "    # img_crop_b = img_crop_b.resize( upscale_2x( img_crop_b ), resample=Image.BOX )\n",
    "    (col_a_name, palette_a) = kmeans_palette(img_crop_a, k=4 )   # -> MyImage_a.kmeans.png\n",
    "    (col_b_name, palette_b) = kmeans_palette(img_crop_b, k=4 )   # -> MyImage_b.kmeans.png\n",
    "\n",
    "    #comparing color\n",
    "    col_a = np.array( get_mean_color( img_crop_a.convert( \"RGB\" ) ) )\n",
    "    col_b = np.array( get_mean_color( img_crop_b.convert( \"RGB\" ) ) )\n",
    "    color_dist = abs( np.linalg.norm( col_a - col_b ) )\n",
    "\n",
    "    #color distance\n",
    "    # if color_dist > args.color_thr:\n",
    "    #    continue\n",
    "\n",
    "    img_crop_a.save( f\"out/{i}a-{col_a_name}.png\" )\n",
    "    palette_a.save( f\"out/{i}a.kmeans.png\" )\n",
    "    img_crop_b.save( f\"out/{i}b-{col_b_name}.png\" )\n",
    "    palette_b.save( f\"out/{i}b.kmeans.png\" )\n",
    "    dist = euclidean_distance( va.center.x, va.center.y, vb.center.x, vb.center.y)\n",
    "    height_diff = abs( va.height - vb.height )\n",
    "    width_diff  = abs( va.width  - vb.width )\n",
    "    theta_diff  = abs( va.theta  - vb.theta )\n",
    "    lst.append( MatchExport( va, vb, dist, color_dist, height_diff, width_diff, theta_diff) )\n",
    "    # print( f\"{dist} = dist( {col_a}, {col_b} )\" )\n",
    "    i += 1\n",
    "\n",
    "vehicle_matches = json.dumps( list( map( lambda el: asdict( el ), lst ) ) )\n",
    "with open( \"matches-sm-3.json\", \"w\" ) as f:\n",
    "    f.write( vehicle_matches )\n",
    "\n",
    "print( f\"There were {len(matches)}\" )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openmmlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
